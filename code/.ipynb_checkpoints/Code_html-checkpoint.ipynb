{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XU7VfXB0L4S7"
   },
   "outputs": [],
   "source": [
    "'''=============================================================== Data directory ==========================================================\n",
    "Reading data from path(given from current directory) drive/ML/Inter-IIT-CSRE  (kindly create and place the data in directory like this)'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#=======================================USE THIS FUNCTION IF LOADING DATA DIRECTLY FROM GOOGLE DRIVE IN GOOGLE COLAB=====================#\n",
    "'''\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "\n",
    "!ls\n",
    "'''\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gxpPRdD-fKxA"
   },
   "outputs": [],
   "source": [
    "# '''==================================================================== Install below libraries =================================================='''\n",
    "# Link : https://pypi.org/project/tifffile/\n",
    "#!pip install tifffile \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQfWQ9uvgJQC"
   },
   "outputs": [],
   "source": [
    "#'''========================================================== Required IMPORTS ========================================================'''\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "\n",
    "from itertools import product,combinations\n",
    "from collections import Counter #Link: https://docs.python.org/2/library/collections.html\n",
    "import h5py #to save model weight\n",
    "import heapq\n",
    "\n",
    "#----------------------------------sklearn import----------------------------#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix,cohen_kappa_score,accuracy_score\n",
    "\n",
    "\n",
    "#-----------------------------------Keras imports----------------------------------------------#\n",
    "\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense,Convolution2D, MaxPooling2D, Flatten, Dense,Activation,average,Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard,EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yy1IKGsf-h29"
   },
   "outputs": [],
   "source": [
    "'''========================================================== Read Image Function ========================================================'''\n",
    "def reading(path,s): #function to read the data where s is aa name of library used for reading images\n",
    "  cou_dir_list = sorted(os.listdir(path))\n",
    "  t = []\n",
    "  for i in range(len(cou_dir_list)):\n",
    "    filename = path + \"/\"+cou_dir_list[i]\n",
    "    if s == \"tiff\":\n",
    "      img = tiff.imread(filename)\n",
    "    elif s == \"cv2\":\n",
    "      img = cv2.imread(filename, 1)\n",
    "    t.append(img)\n",
    "  print(\"Data len:\",len(t),\"        Shape of 1st ele:\",t[0].shape)\n",
    "  return t\n",
    "'''----------------------------------------------------------------------------------------------------------------------------------------'''\n",
    "\n",
    "\n",
    "\n",
    "'''========================================================== scale_percentile Function ========================================================'''\n",
    "def scale_percentile(matrix):     #Function to convert the given 4 band image to png uint8 image.\n",
    "    \"\"\"Fixes the pixel value range to 2%-98% original distribution of values\"\"\"\n",
    "    orig_shape = matrix.shape\n",
    "    matrix = np.reshape(matrix, [matrix.shape[0]*matrix.shape[1], 3]).astype(float)\n",
    "    # Get 2nd and 98th percentile\n",
    "    mins = np.percentile(matrix, 1, axis=0)\n",
    "    maxs = np.percentile(matrix, 99, axis=0) - mins\n",
    "    \n",
    "    matrix = (matrix - mins[None,:])/maxs[None,:]\n",
    "    matrix = np.reshape(matrix, orig_shape)\n",
    "    matrix = matrix.clip(0,1)\n",
    "    return matrix\n",
    "'''---------------------------------------------------------------------------------------------------------------------------------------'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''========================================================== Plot RGB Function ========================================================'''\n",
    "def plot(img , title): #Function to plot png image\n",
    "    fig = plt.figure(figsize = (18 , 18))\n",
    "    ax = fig.subplots(nrows=1, ncols=2)\n",
    "    ax[0].imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) \n",
    "    plt.title (title + \",       Shape:\"+ str(img.shape))\n",
    "# plot(y[0],\"Label\") #use like this\n",
    "'''---------------------------------------------------------------------------------------------------------------------------------------'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''========================================================== Plot TIF Function ========================================================'''\n",
    "def plottiff(z,title):#Function to plot .tif format image\n",
    "  tif_data = z[:,:,:3]\n",
    "  img = scale_percentile(tif_data)\n",
    "  plt.imshow(img)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([]) \n",
    "  plt.title (title + \"     Shape:\"+ str(img.shape))\n",
    "  plt.show()\n",
    "# plottiff(x[0],\"Actual\") #use like this\n",
    "'''---------------------------------------------------------------------------------------------------------------------------------------'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-fKNhNO-8bA"
   },
   "outputs": [],
   "source": [
    "'''###======================================================== READ IMAGES =============================================================='''\n",
    "\n",
    "x = reading(\"drive/ML/Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/sat\",\"tiff\")\n",
    "y = reading(\"drive/ML/Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt\",\"cv2\")\n",
    "test_images = reading(\"drive/ML/Inter-IIT-CSRE/The-Eye-in-the-Sky-test-data/sat_test\",\"tiff\")\n",
    "somefile = \"drive/ML/Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/sat/1.tif\"\n",
    "nx = len(x) #no. of train images \n",
    "nytest = len(test_images)#no. of test images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7Y3Yh7YgHES"
   },
   "outputs": [],
   "source": [
    "'''###============================== DICTIONARY for png colour value from id and viceversa e.g id = 0 and png = (255,255,255)===================================================================###'''\n",
    "\n",
    "unique = []\n",
    "for img in y:\n",
    "  for i in range(img.shape[0]):\n",
    "    for j in range(img.shape[1]):\n",
    "      ele = (img[i,j,0],img[i,j,1],img[i,j,2])\n",
    "      if ele not in unique:\n",
    "        unique.append(ele)\n",
    "\n",
    "pixeltoid = dict(zip(unique, range(9)))\n",
    "idtopixel = dict(zip(range(9),unique))\n",
    "\n",
    "'''\n",
    "[(255, 255, 255), white                  - NOTHING/other class\n",
    " (100, 100, 100), gray                   - building\n",
    " (0, 0, 0),       black                  - roads\n",
    " (0, 255, 0),     light green            - grass\n",
    " (0, 125, 0),     dark green             - trees\n",
    " (0, 255, 255),   light blue             - railway\n",
    " (0, 80, 150),    dark blue              - Bare soil\n",
    " (255, 150, 150), light pink             - pool\n",
    " (150, 0, 0)]     Brown                  - water\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''###================================================ REPLACE COLOUR WITH ID ================================================================###'''\n",
    "\n",
    "ymask = []   #2d reprasentaion of image label by replacing png colour with thier id\n",
    "for ele in y:\n",
    "  temp = np.zeros((ele.shape[0],ele.shape[1]))\n",
    "  for i,j in product(range(ele.shape[0]),range(ele.shape[1])):\n",
    "    temp[i,j] = pixeltoid[tuple(ele[i,j,:])]\n",
    "  ymask.append(temp)\n",
    "# print(len(ymask),ymask[0].shape) #use it like this\n",
    "\n",
    "\n",
    "\n",
    "'''###================================================ REPLACE ID WITH VECTOR DICT ===================================================================###'''\n",
    "#One hot encoding for each color id\n",
    "\n",
    "t1 = np.array([i for i in range(9)])\n",
    "encoder = LabelBinarizer()\n",
    "t2 = encoder.fit_transform(t1)\n",
    "t3 = []\n",
    "for ele in t2:\n",
    "  t3.append(tuple(ele))\n",
    "\n",
    "vectortoid = dict(zip(t3, range(9)))\n",
    "idtovector = dict(zip(range(9),t3))\n",
    "\n",
    "\n",
    "\n",
    "#vectortoid[(0,0,0,0,1,0,0,0,0)],list(idtovector[7]) #use it like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLUjwlC78bne"
   },
   "outputs": [],
   "source": [
    "'''###================================================ SET PARAMETERS HERE ==================================================###'''\n",
    "patch_size = 4  #size of patch used for training cnn\n",
    "stride = 4      #Stride used for creating above patches\n",
    "\n",
    "n_epochs = 50   #Number of epoch in training\n",
    "batch_size=128  #batch_size in training\n",
    "\n",
    "alphawhite = 1  # (in range (1,INFINITY))  #parameter to control false positive of white class.Increase alphawhite if want to decrease false positive of white class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkDvPysklzQd"
   },
   "outputs": [],
   "source": [
    "'''###================================================ create_patches and create_lbls FUNCTON ==================================================###'''\n",
    "def create_patches(img,patch_size,stride):   #FUNCTION TO CREATE PATCH FOR 4 BAND TRAINING AND TESTING IMAGES \n",
    "  nrow, ncol = img.shape[0],img.shape[1]\n",
    "  i_startlist,i_endlist = np.arange(0, nrow-patch_size+1, stride),np.arange(0+patch_size, nrow, stride)\n",
    "  j_startlist,j_endlist = np.arange(0, ncol-patch_size+1, stride),np.arange(0+patch_size, ncol, stride)\n",
    "  patch_list = list()\n",
    "  for istart, iend in zip(i_startlist, i_endlist):\n",
    "      for jstart, jend in zip(j_startlist, j_endlist):\n",
    "        patch_list.append(img[istart:iend, jstart:jend,:])\n",
    "  patches1 = np.array(patch_list)\n",
    "#   print(\"Input img shape:\",img.shape,\"Patches shape:\",patches1.shape) #use if you want size patch and number of created patches\n",
    "  return patches1\n",
    "\n",
    "\n",
    "'''-----------------------------------------------------------------------------------------------------------------------------------------------'''\n",
    "\n",
    "\n",
    "def create_lbls(mask,patch_size,stride):#FUNCTION TO CREATE PATCH AND HENCE MAXCOLOUR COLUR ONE HOT ENCODE, FOR 3 BAND TRAINING AND TESTING IMAGES \n",
    "  nrow, ncol = mask.shape[0],mask.shape[1]\n",
    "  i_startlist,i_endlist = np.arange(0, nrow-patch_size+1, stride),np.arange(0+patch_size, nrow, stride)\n",
    "  j_startlist,j_endlist = np.arange(0, ncol-patch_size+1, stride),np.arange(0+patch_size, ncol, stride)\n",
    "  lbl_list = list()\n",
    "  for istart, iend in zip(i_startlist, i_endlist):\n",
    "      for jstart, jend in zip(j_startlist, j_endlist):\n",
    "        \n",
    "          lbl_list.append(list(idtovector[Counter(mask[istart:iend, jstart:jend].flatten()).most_common(1)[0][0]]))\n",
    "  \n",
    "  lbls1 = np.array(lbl_list)\n",
    "#   print(\"Input img shape:\",mask.shape,\"lbls shape:\",lbls1.shape)#use if you want size patch and number of created patches\n",
    "  \n",
    "  return lbls1\n",
    "  \n",
    "# patches = create_patches(x[0]) #USE THEM LIKE THIS\n",
    "# lbls = create_lbls(ymask[0])   #USE THEM LIKE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OBHrgtg3Jllr"
   },
   "outputs": [],
   "source": [
    "'''###================================ CREATE PATCHES FOR TRAINING AND TEST DATA, & LBLS FOR TRAINING DATA =========================================###'''\n",
    "\n",
    "xpatches = []\n",
    "test_images_patches = []\n",
    "lblslist = []\n",
    "\n",
    "for i,ele in enumerate(x):\n",
    "  patches = create_patches(ele,patch_size,stride)\n",
    "  xpatches.append(patches)\n",
    "for ele in ymask:\n",
    "  lbls = create_lbls(ele,patch_size,stride)\n",
    "  lblslist.append(lbls)\n",
    "for ele in test_images:\n",
    "  patches = create_patches(ele,patch_size,stride)\n",
    "  test_images_patches.append(patches)\n",
    "  \n",
    "xpatches = np.array(xpatches)\n",
    "test_images_patches = np.array(test_images_patches)\n",
    "lblslist = np.array(lblslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0etELnpj5OS_"
   },
   "outputs": [],
   "source": [
    "xpatches_ = xpatches[0]\n",
    "lblslist_ = lblslist[0]\n",
    "for i in range(1,nx):\n",
    "  xpatches_ = np.concatenate((xpatches_, xpatches[i]), axis=0)\n",
    "  lblslist_ = np.concatenate((lblslist_, lblslist[i]), axis=0)\n",
    "# print(xpatches_.shape,lblslist_.shape)\n",
    "\n",
    "# xpatches_    : Similar to x DATA FOR MODEL\n",
    "# lblslist_    : Similar to Y DATA FOR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8i2SydwVHFf4"
   },
   "outputs": [],
   "source": [
    "'''###================================================ CREATE MODEL FUNCTON ==================================================###'''\n",
    "def create_model():  #FUNCTION TO CREATE KERAS MODEL\n",
    "  \n",
    "  #model\n",
    "  model = Sequential()\n",
    "  \n",
    "  #Convolution layer 1\n",
    "  model.add(Convolution2D(64, 1, 1, border_mode='same', input_shape=(patch_size, patch_size, 4), dim_ordering=\"tf\"))\n",
    "  model.add(BatchNormalization(mode=0))\n",
    "  model.add(Activation(\"relu\"))\n",
    "  \n",
    "  #pooling\n",
    "  model.add(MaxPooling2D((2,2), dim_ordering=\"tf\"))\n",
    "  \n",
    "  #Convolution layer 2\n",
    "  model.add(Convolution2D(64, 1, 1, border_mode='same', dim_ordering=\"tf\"))\n",
    "  model.add(BatchNormalization(mode=0))\n",
    "  model.add(Activation(\"relu\"))\n",
    "  \n",
    "  #Convolution layer 3\n",
    "  model.add(Convolution2D(128, 3, 3, border_mode='same', dim_ordering=\"tf\"))\n",
    "  model.add(BatchNormalization(mode=0))\n",
    "  model.add(Activation(\"relu\"))\n",
    "  \n",
    "  #pooling\n",
    "  model.add(MaxPooling2D((2,2), dim_ordering=\"tf\"))\n",
    "  \n",
    "  #fully connected laye\n",
    "  model.add(Flatten())\n",
    "  \n",
    "  # output layer\n",
    "  model.add(Dense(9,activation=\"softmax\", name='output_layer'))\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy',optimizer= optimizers.Nadam(lr = 0.002),metrics=['accuracy'])\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yhu7fVqiNcEs"
   },
   "outputs": [],
   "source": [
    "'''###================================================ VISUALIZATION TRAINING FUNCTON ==================================================###'''\n",
    "def visualize(hist):   #FUNCTION TO VISUALISE EPOCH DURING TRAINING\n",
    "  \n",
    "    temp_epochs = len(hist.history['loss'])\n",
    "    \n",
    "    # visualizing losses and accuracy\n",
    "    train_loss=hist.history['loss']\n",
    "    val_loss=hist.history['val_loss']\n",
    "    train_acc=hist.history['acc']\n",
    "    val_acc=hist.history['val_acc']\n",
    "    xc=range(temp_epochs)\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(1,figsize=(7,5))\n",
    "    plt.plot(xc,train_loss)\n",
    "    plt.plot(xc,val_loss)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('train_loss vs val_loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(2,figsize=(7,5))\n",
    "    plt.plot(xc,train_acc)\n",
    "    plt.plot(xc,val_acc)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('train_acc vs val_acc')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'],loc=4)\n",
    "    #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvvjQoyrR7a8"
   },
   "outputs": [],
   "source": [
    "'''###================================================ TRAINING FUNCTON ==================================================###'''\n",
    "\n",
    "def train():           #FUNCTION TO TRAIN MODEL\n",
    "  filename = 'modelsaved_once.h5'\n",
    "    \n",
    "  checkpoint = ModelCheckpoint(filename, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "  earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
    "  ReduceLROnPlateau_callback = ReduceLROnPlateau(monitor='val_acc', factor=0.5,patience=3,verbose=1, min_lr=0.0001, mode='auto')\n",
    "  callbacks_list = [checkpoint,earlystop,ReduceLROnPlateau_callback]\n",
    "\n",
    "      \n",
    "  patches = xpatches_\n",
    "  lbls = lblslist_\n",
    "  model = create_model()\n",
    "\n",
    "  xtrain, xval, ytrain, yval = train_test_split(patches, lbls,train_size=0.8,test_size=0.2,random_state=2,shuffle=True)\n",
    "  t=time.time()\n",
    "  hist = model.fit(xtrain, ytrain, batch_size=batch_size, epochs=n_epochs, verbose=1, validation_data=(xval, yval), callbacks=callbacks_list)\n",
    "  print('Training time: %s' % (t - time.time()))\n",
    "\n",
    "  model = load_model(filename)\n",
    "  (loss, accuracy) = model.evaluate(xval, yval, batch_size=batch_size, verbose=1)\n",
    "  print(\"\\n[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
    "\n",
    "  visualize(hist)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YooBA7gT4d-"
   },
   "outputs": [],
   "source": [
    "'''###================================================ TRAINING in kfold FUNCTON ==================================================###'''\n",
    "\n",
    "def train_kfold(n_folds):\n",
    "  patches = xpatches_\n",
    "  lbls = lblslist_\n",
    "      \n",
    "  skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=None)\n",
    "  modellist = []\n",
    "  for i, (train_idx, val_idx) in enumerate(skf.split(patches,lbls.argmax(1))):\n",
    "      print(\"****************Running Fold \", i+1, \"/\", n_folds,\"**************\")\n",
    "      \n",
    "      \n",
    "      filename = \"modelsaved_kfold_\"+str(i+1)+\".h5\"\n",
    "\n",
    "      checkpoint = ModelCheckpoint(filename, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "      earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
    "      ReduceLROnPlateau_callback = ReduceLROnPlateau(monitor='val_acc', factor=0.5,patience=3,verbose=1, min_lr=0.0000001, mode='auto')\n",
    "      callbacks_list = [checkpoint,earlystop,ReduceLROnPlateau_callback]\n",
    "      \n",
    "      \n",
    "      xtrain, xval, ytrain, yval = patches[train_idx], patches[val_idx], lbls[train_idx], lbls[val_idx] #train_test_split(patches[], lbls,train_size=0.8,test_size=0.2,random_state=2,shuffle=True)  \n",
    "      model = None  \n",
    "      model = create_model()\n",
    "      t=time.time()\n",
    "      hist = model.fit(xtrain, ytrain, batch_size=batch_size, epochs=n_epochs, verbose=1, validation_data=(xval, yval), callbacks=callbacks_list)\n",
    "      print('Training time: %s' % (t - time.time()))\n",
    "      \n",
    "      \n",
    "      \n",
    "      model = load_model(filename)\n",
    "      (loss, accuracy) = model.evaluate(xval, yval, batch_size=batch_size, verbose=1)\n",
    "      print(\"\\n[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
    "\n",
    "      visualize(hist)\n",
    "      modellist.append(modellist)\n",
    "  return modellist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rYSAKvH6Xjyd",
    "outputId": "46277d88-7494-4a8c-fd2b-beea0d98e88e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'###=================================================================== Train without kfold cross validification(Quick) ================================================================###'"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''###=================================================================== Train without kfold cross validification(Quick) ================================================================###'''\n",
    "model = train() # CALLING TRAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heSIEyPMp-sq"
   },
   "outputs": [],
   "source": [
    "'''###=================================================================== Train with kfold cross validification(Too much time taking) ================================================================###'''\n",
    "n_folds = 2\n",
    "modellist = train_kfold(n_folds) #Use this for kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNE8rzimtsHd"
   },
   "outputs": [],
   "source": [
    "# model = load_model('modelsaved_once.h5') #LOAD BEST MODEL SO FAR IF ABOVE TRAINING PROCESS IS TERMINATED DUE TO RUN TIME DIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZBIoTuxcqFz"
   },
   "outputs": [],
   "source": [
    "'''###================================================ PREDICT FUNCTON ==================================================###'''\n",
    "\n",
    "def predict(model,index,sflag,pflag,alphawhite): #FUNCTION TO PREDICT THE OUTPUT\n",
    "  \n",
    "  '''\n",
    "  index : index of image to predict from data\n",
    "  sflag : take image from test dataset if sflag = \"test\" else if sflag = \"train\" then take from train dataset\n",
    "  pflag : == \"yes\" if you want to visualise image ,else \"no\"\n",
    "  alphawhite > 1: Increase alphawhite if want to decrease false positive of white class\n",
    "  '''\n",
    "  \n",
    "  if sflag == \"train\":\n",
    "    patches,real = xpatches[index],x[index]\n",
    "  elif sflag == \"test\":\n",
    "    patches,real = test_images_patches[index],test_images[index]\n",
    "  else:\n",
    "    print(\"WRANING : Wrong Input\")\n",
    "    return\n",
    "\n",
    "  \n",
    "  out = model.predict(patches,batch_size=32, verbose=False, steps=None)\n",
    "  \n",
    "  \n",
    "  nrow, ncol = real.shape[0],real.shape[1]\n",
    "  i_ = np.arange(0, nrow, patch_size)\n",
    "  j_ = np.arange(0, ncol, patch_size)\n",
    "  newimg = np.zeros((nrow,ncol,3),dtype = 'uint8')  #'uint8' !!! defalut is float64\n",
    "  count = 0\n",
    "  for istart, iend in zip(i_[:-1], i_[1:]):\n",
    "      for jstart, jend in zip(j_[:-1], j_[1:]):\n",
    "        twoele = heapq.nlargest(2, out[count])\n",
    "        if twoele[0] == 0:\n",
    "          if twoele[0]/twoele[1] > alphawhite :\n",
    "            p = np.where(out[count] == twoele[0])[0][0]\n",
    "          else:\n",
    "            p = np.where(out[count] == twoele[1])[0][0]\n",
    "        else:\n",
    "          p = np.where(out[count] == twoele[0])[0][0]\n",
    "        for i in range(0,patch_size):\n",
    "          for j in range(0,patch_size):\n",
    "            for k in range(3):\n",
    "              newimg[istart+i,jstart+j,k] = idtopixel[p][k]\n",
    "        count+=1\n",
    "  \n",
    "  if pflag == \"yes\":\n",
    "    plot(newimg,\"Predicted\")\n",
    "    plottiff(real,\"Real Image\")\n",
    "    if sflag == \"train\":\n",
    "      plot(y[index],\"Given label\")\n",
    "    \n",
    "       \n",
    "  return (newimg,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHJP0CCuSx43"
   },
   "outputs": [],
   "source": [
    "'''###================================================ CALLING PREDICT FUNCTON ON TRAINING IMAGE ==================================================###'''\n",
    "train_pred = []\n",
    "for i in range(nx):\n",
    "  (newimage,out) = predict(model,i,\"train\",\"yes\",alphawhite)\n",
    "  train_pred.append(newimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-GO27uxR1QD"
   },
   "outputs": [],
   "source": [
    "'''###================================================ CALLING PREDICT FUNCTON ON TESTING IMAGE ==================================================###'''\n",
    "test_pred = []\n",
    "for i in range(nytest):\n",
    "  (newimage,out) = predict(model,i,\"test\",\"yes\",alphawhite)\n",
    "  test_pred.append(newimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fZ0_x3CUyKI"
   },
   "outputs": [],
   "source": [
    "#=============If using kfold then predict like this by each model combine and take average of output genrated by all models.=============\n",
    "outlist = []\n",
    "final_out = None\n",
    "i = 0 #index of image to predict\n",
    "\n",
    "for temp_model in modellist:\n",
    "  (newimage,out) = predict(model,i,\"test\",\"no\",alphawhite)\n",
    "  outlist.append(out)\n",
    "  \n",
    "final_out = outlist[0] + outlist[1]  #ensembling the output of 0th and 1st model\n",
    "# ==========================================================================================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#================================= Ensembling model to one model if trained in kfold================================#\n",
    "'''\n",
    "def ensembleModels(modellist, model_input):\n",
    "    # collect outputs of models in a list\n",
    "    yModels=[model(model_input) for model in modellist] \n",
    "\n",
    "    # averaging outputs\n",
    "    yAvg=layers.average(yModels) \n",
    "\n",
    "    # build model from same input and avg output\n",
    "    modelEns = Model(inputs=model_input, outputs=yAvg,    name='ensemble')  \n",
    "   \n",
    "    return modelEns\n",
    "\n",
    "\n",
    "model_input = Input(shape=(modellist[0]).input_shape[1:]) # c*h*w\n",
    "modelEns = ensembleModels(modellist, model_input)\n",
    "modelEns.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m90A1swQhbUh"
   },
   "outputs": [],
   "source": [
    "# model.save(\"drive/ML/sat_image_saved_model/modelsaved_once.h5\")  #SAVE MODEL WEIGHT TO USE LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpJfj9WBSOdd"
   },
   "outputs": [],
   "source": [
    "# =================================================== FUNCTION TO SMOOTHEN THE IMAGE FOR BETTER VISULISATION ========================================#\n",
    "def smooth(real,startp,smooth_patch):\n",
    "  realmask = np.zeros((real.shape[0],real.shape[1]))\n",
    "  for i,j in product(range(real.shape[0]),range(real.shape[1])):\n",
    "    realmask[i,j] = pixeltoid[tuple(real[i,j,:])]\n",
    "  nrow, ncol = real.shape[0],real.shape[1]\n",
    "  i_ = np.arange(startp, nrow, smooth_patch)\n",
    "  j_ = np.arange(startp, ncol, smooth_patch)\n",
    "  newimg = np.zeros((nrow,ncol,3),dtype = 'uint8')  #'uint8' !!! defalut is float64\n",
    "  for istart, iend in zip(i_[:-1], i_[1:]):\n",
    "      for jstart, jend in zip(j_[:-1], j_[1:]):\n",
    "        for i in range(0,smooth_patch):\n",
    "          for j in range(0,smooth_patch):\n",
    "            for k in range(3):\n",
    "              a = idtopixel[Counter(realmask[istart:iend, jstart:jend].flatten()).most_common(1)[0][0]][k]\n",
    "              newimg[istart+i,jstart+j,k] = a\n",
    "  return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOaQCWWLZpPG"
   },
   "outputs": [],
   "source": [
    "# =================================================== Printing smoothen function ========================================#\n",
    "\n",
    "img = test_pred[0] #image to smoothen\n",
    "startp = 1 # i.e i>=1 and j>=1 while smoothing image\n",
    "smooth_patch = 2 # smoothening filter size\n",
    "smoothen_png_image = smooth(img,startp,smooth_patch)\n",
    "\n",
    "plot(smoothen_png_image,\"Smoothen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjC_IByif2Iv"
   },
   "outputs": [],
   "source": [
    "#============================================ Function to create 2d mask array of 3 band png labels array ======================================#\n",
    "def ymasks(y):\n",
    "  ymask1 = []\n",
    "  for ele in y:\n",
    "    temp = np.zeros((ele.shape[0],ele.shape[1]))\n",
    "    for i,j in product(range(ele.shape[0]),range(ele.shape[1])):\n",
    "      temp[i,j] = pixeltoid[tuple(ele[i,j,:])]\n",
    "    ymask1.append(temp)\n",
    "  return np.array(ymask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46L6kCJ3ggh4"
   },
   "outputs": [],
   "source": [
    "#============================================ Function to calculate Confusion matrix, Confusion matrix report, Kappa coefficient and overallacc ======================================#\n",
    "\n",
    "def accuracy(y,y_):  \n",
    "  \n",
    "  y_actu = ymasks(y)\n",
    "  y_pred = ymasks(y_)\n",
    "  \n",
    "  y_actulist = []\n",
    "  y_predlist = []\n",
    "  \n",
    "\n",
    "  for k in range(len(y_actu)):\n",
    "    for ele in y_actu[k].flatten():\n",
    "      y_actulist.append(ele)\n",
    "\n",
    "    for ele in y_pred[k].flatten():\n",
    "      y_predlist.append(ele)\n",
    "\n",
    "  cm = confusion_matrix(y_actulist, y_predlist)\n",
    "#   print(cm)\n",
    "\n",
    "#   print(Counter(y_actulist)) #frequency of colour in y_actulist\n",
    "#   print(Counter(y_predlist)) #frequency of colour in y_predlist\n",
    "\n",
    "  target_names = []\n",
    "  for j in range(max(len(Counter(y_actulist)),len(Counter(y_predlist)))):\n",
    "    target_names.append(str(j))\n",
    "\n",
    "  cm_report = classification_report(y_actulist, y_predlist, target_names=target_names)\n",
    "#   print(cm_report)\n",
    "\n",
    "  kappa = cohen_kappa_score(y_actulist, y_predlist, labels=None, weights=None, sample_weight=None)\n",
    "  overallacc = accuracy_score(y_actulist, y_predlist,  normalize=True,sample_weight=None)\n",
    "  print(kappa,overallacc)\n",
    "  \n",
    "  return (cm, cm_report,kappa,overallacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZ6EKKXdifgu"
   },
   "outputs": [],
   "source": [
    "#============================================ Printing Confusion matrix, Confusion matrix report, Kappa coefficient and overallacc ======================================#\n",
    "(cm, cm_report,kappa,overallacc) = accuracy(y,train_pred)\n",
    "\n",
    "print(\"Confusion matrix:\\n\",cm)\n",
    "print(\" \\nConfusion matrix report:\\n\",cm_report)\n",
    "print(\"\\nkappa coefficient:\\n\",kappa)\n",
    "print(\"\\noverallacc:\\n\",overallacc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Code_ipython.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
